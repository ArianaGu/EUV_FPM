{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import display, clear_output\n",
    "from colorsys import hls_to_rgb\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# System parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# size of the region of interest\n",
    "roi_size_px = 332*3\n",
    "# wavelength of acquisition\n",
    "lambda_m = 13.5e-9\n",
    "\n",
    "# effective pixel size\n",
    "dx_m = 15e-9\n",
    "# effective field size\n",
    "Dx_m = roi_size_px * dx_m\n",
    "\n",
    "# spatial scales\n",
    "x_m = np.arange(1, roi_size_px + 1) * dx_m\n",
    "y_m = np.arange(1, roi_size_px + 1) * dx_m\n",
    "\n",
    "# angular frequency scale\n",
    "fs = 1 / (x_m[1] - x_m[0])\n",
    "Nfft = len(x_m)\n",
    "df = fs / Nfft\n",
    "freq_cpm = np.arange(0, fs, df) - (fs - Nfft % 2 * df) / 2\n",
    "\n",
    "# frequency cut-off of the lens (0.33 4xNA lens)\n",
    "fc_lens = (np.arcsin(.33/4)/lambda_m)\n",
    "# lens pupil filter in reciprocal space\n",
    "Fx, Fy = np.meshgrid(freq_cpm, freq_cpm)\n",
    "FILTER = (Fx**2 + Fy**2) <= fc_lens**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Metric function\n",
    "Implement the Fourier Ring Correlation in http://doi.org/10.1038/nmeth.2448"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the images\n",
    "folder = './sim_data/bprp_abe00/'\n",
    "generate_matlab_dataset= True\n",
    "keyword = 'tile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "# Find all .png files in the folder\n",
    "files = glob.glob(os.path.join(folder, \"*.png\"))\n",
    "\n",
    "img = []\n",
    "sx = []\n",
    "sy = []\n",
    "\n",
    "if generate_matlab_dataset:\n",
    "    I_low_stack = []\n",
    "    na_calib = []\n",
    "    na_cal = fc_lens*lambda_m   # NA without dimension\n",
    "    na_rp_cal = fc_lens*Dx_m    # NA in pixels\n",
    "\n",
    "for filename in files:\n",
    "    img_0 = np.array(Image.open(filename)).astype(float)\n",
    "    img.append(img_0)\n",
    "    filename = os.path.basename(filename)\n",
    "    # sx_0 = float(filename[-17:-12])\n",
    "    sx_0 = float(filename[-20:-15])\n",
    "    sy_0 = float(filename[-9:-4])\n",
    "    sx.append(sx_0)\n",
    "    sy.append(sy_0)\n",
    "    if generate_matlab_dataset:\n",
    "        I_low_stack.append(img_0)\n",
    "        na_calib.append([sx_0*fc_lens*lambda_m, sy_0*fc_lens*lambda_m])\n",
    "\n",
    "if generate_matlab_dataset:\n",
    "    I_low = np.stack(I_low_stack, axis=2)\n",
    "    na_calib = np.array(na_calib)\n",
    "    freqXY_calib = na_calib*na_rp_cal/na_cal+roi_size_px/2+1 # Shift to the center of the FOV\n",
    "    scipy.io.savemat(f'{folder}/{keyword}.mat', {'I_low': I_low, 'freqXY_calib': freqXY_calib, 'na_calib': na_calib,\n",
    "                                                'na_cal': na_cal, 'na_rp_cal': na_rp_cal})\n",
    "print(len(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize illumination pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the scatter plot\n",
    "plt.scatter(sx, sy)\n",
    "plt.xlabel('sx')\n",
    "plt.ylabel('sy')\n",
    "plt.title('FPM illumination pattern')\n",
    "# Setting axis limits\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save as meas pattern for simulation\n",
    "meas = []\n",
    "for i in range(len(sx)):\n",
    "    meas.append([sx[i], sy[i]])\n",
    "    \n",
    "import pickle\n",
    "with open(f'{folder}/meas.pkl', 'wb') as f:\n",
    "    pickle.dump(meas, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zernike_polynomial(n, m, pupil):\n",
    "    def polar_coords():\n",
    "        \"\"\"Generate polar coordinates for a given size\"\"\"\n",
    "        x = np.linspace(-1, 1, cmax-cmin+1)\n",
    "        y = np.linspace(-1, 1, rmax-rmin+1)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        R = np.sqrt(X**2 + Y**2)\n",
    "        T = np.arctan2(Y, X)\n",
    "        T = np.where(T < 0, T + 2*np.pi, T)\n",
    "        return R, T\n",
    "\n",
    "    def radial_poly(n, m, R):\n",
    "        \"\"\"Calculate the radial polynomial\"\"\"\n",
    "        radial = np.zeros_like(R)\n",
    "        for s in range((n - abs(m)) // 2 + 1):\n",
    "            coef = (-1)**s * np.math.factorial(n - s)\n",
    "            coef /= np.math.factorial(s) * np.math.factorial((n + abs(m)) // 2 - s) * np.math.factorial((n - abs(m)) // 2 - s)\n",
    "            radial += coef * R**(n - 2 * s)\n",
    "        return radial\n",
    "\n",
    "    rows = np.any(pupil, axis=1)\n",
    "    cols = np.any(pupil, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    R, T = polar_coords()\n",
    "    Radial = radial_poly(n, m, R)\n",
    "    if m > 0:\n",
    "        Z = np.sqrt(2*n+2) * Radial * np.cos(m * T)\n",
    "    elif m < 0:\n",
    "        Z = -np.sqrt(2*n+2) * Radial * np.sin(m * T)\n",
    "    else:\n",
    "        Z = np.sqrt(n+1) * Radial\n",
    "\n",
    "    # Pad the Zernike polynomial to match the full pupil size\n",
    "    padded_Z = np.zeros(pupil.shape)\n",
    "    padded_Z[rmin:rmax+1, cmin:cmax+1] = Z\n",
    "    return padded_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lens_init(FILTER, option='plane', file_name=\"\"):\n",
    "    FILTER = np.double(FILTER)\n",
    "    if option == 'plane':\n",
    "        lens_init = FILTER\n",
    "        abe = np.zeros(FILTER.shape)\n",
    "    elif option == 'zernike':\n",
    "        defocus_coef = 0.15\n",
    "        coma_coef = [0.075,0.075]\n",
    "        defocus = zernike_polynomial(2, 0, FILTER)\n",
    "        coma1 = zernike_polynomial(3, 1, FILTER)\n",
    "        coma2 = zernike_polynomial(3, -1, FILTER)\n",
    "        abe = (defocus_coef*defocus+ coma_coef[0]*coma1 + coma_coef[1]*coma2)*FILTER\n",
    "        lens_guess = FILTER * np.exp(1j*abe)\n",
    "        lens_init = lens_guess\n",
    "    elif option == 'file':\n",
    "        abe = np.load(file_name)\n",
    "        lens_init = FILTER * np.exp(1j*abe)\n",
    "    else:\n",
    "        raise ValueError('option must be either plane, zernike, or file')\n",
    "    show_aberration(abe, FILTER)\n",
    "    return lens_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recon parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ROI = True\n",
    "ROI_length = 256\n",
    "ROI_center =  [int(roi_size_px/2), int(roi_size_px/2-30)]\n",
    "init_option = 'plane'\n",
    "file_name = f'{folder}/gt_abe.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_ROI:\n",
    "    roi_size_px = min(ROI_length, roi_size_px)\n",
    "    print(f'Using ROI of size {ROI_length}')\n",
    "    x_m = x_m[ROI_center[0]-int(ROI_length/2):ROI_center[0]+int(ROI_length/2)]\n",
    "    y_m = y_m[ROI_center[1]-int(ROI_length/2):ROI_center[1]+int(ROI_length/2)]\n",
    "    img = [i[ROI_center[0]-int(ROI_length/2):ROI_center[0]+int(ROI_length/2), \n",
    "             ROI_center[1]-int(ROI_length/2):ROI_center[1]+int(ROI_length/2)] for i in img]\n",
    "    Dx_m = x_m.max() - x_m.min()\n",
    "    dx_m = Dx_m / ROI_length\n",
    "    fs = 1 / dx_m\n",
    "    Nfft = len(x_m)\n",
    "    df = fs / Nfft\n",
    "    freq_cpm = np.arange(0, fs, df) - (fs - Nfft % 2 * df) / 2\n",
    "    Fx, Fy = np.meshgrid(freq_cpm, freq_cpm)\n",
    "    FILTER = (Fx**2 + Fy**2) <= fc_lens**2\n",
    "\n",
    "lens_init = get_lens_init(FILTER, init_option, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDUpdate_Multiplication_rank1(O, P, dpsi, Omax, cen, Ps, alpha, beta, step_size):\n",
    "    Np = np.array(P.shape).ravel()\n",
    "    cen = cen.ravel()\n",
    "    n1 = cen - np.floor(Np / 2)\n",
    "    n2 = n1 + Np - 1\n",
    "    n1 = n1.astype(int)\n",
    "    n2 = n2.astype(int)\n",
    "    O1 = O[n1[0]:n2[0]+1, n1[1]:n2[1]+1]\n",
    "\n",
    "    O[n1[0]:n2[0]+1, n1[1]:n2[1]+1] += step_size * 1 / np.max(np.abs(P)) * np.abs(P) * np.conj(P) * dpsi / (np.abs(P) ** 2 + alpha)\n",
    "    P += 1 / Omax * (np.abs(O1) * np.conj(O1)) * dpsi / (np.abs(O1) ** 2 + beta) * Ps\n",
    "\n",
    "    return O, P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming I_low is a 3D numpy array and freqXY_calib is a 2D numpy array provided beforehand\n",
    "Nx, Ny, Nimg = I_low.shape\n",
    "\n",
    "enableROI = True  # whether to use ROI in the reconstruction\n",
    "ROILength = 256  # define the ROI of the reconstruction\n",
    "ROIcenter = [round(Nx / 2), round(Ny / 2)]\n",
    "paddingHighRes = 3\n",
    "\n",
    "x_illumination = freqXY_calib[:, 1]  # note the second column is assigned to x\n",
    "y_illumination = freqXY_calib[:, 0]  # note the first column is assigned to y\n",
    "xc = round(Ny / 2)\n",
    "yc = round(Nx / 2)\n",
    "x_illumination -= xc\n",
    "y_illumination -= yc\n",
    "\n",
    "# crop ROI\n",
    "if enableROI:\n",
    "    x_illumination *= ROILength / Nx\n",
    "    y_illumination *= ROILength / Ny\n",
    "    I = I_low[ROIcenter[0] - ROILength // 2: ROIcenter[0] + ROILength // 2,\n",
    "              ROIcenter[1] - ROILength // 2: ROIcenter[1] + ROILength // 2, :]\n",
    "    Np = ROILength\n",
    "    X, Y = np.meshgrid(np.arange(1, Np + 1), np.arange(1, Np + 1))\n",
    "    xc = round(Np / 2)\n",
    "    yc = round(Np / 2)\n",
    "else:\n",
    "    I = I_low\n",
    "    Np = Nx\n",
    "    X, Y = np.meshgrid(np.arange(1, Ny + 1), np.arange(1, Nx + 1))\n",
    "    xc = round(Ny / 2)\n",
    "    yc = round(Nx / 2)\n",
    "\n",
    "distanceFromCenter = np.sqrt((X - xc)**2 + (Y - yc)**2)\n",
    "w_NA = distanceFromCenter <= na_rp_cal * (ROILength / Nx if enableROI else 1)\n",
    "\n",
    "Ns2 = np.stack((x_illumination, y_illumination), axis=-1)\n",
    "Ns2 = Ns2.reshape(1, Nimg, 2)\n",
    "Ns = np.round(Ns2)\n",
    "\n",
    "N_obj = paddingHighRes * Np\n",
    "def upsamp(x):\n",
    "    pad_height = (N_obj - Np[0]) // 2\n",
    "    pad_width = (N_obj - Np[1]) // 2\n",
    "    padding = ((pad_height, pad_height), (pad_width, pad_width))\n",
    "    return np.pad(x, padding, mode='constant')\n",
    "\n",
    "def downsamp(x, cen, Np):\n",
    "    start_row = int(cen[0] - Np[0] // 2)\n",
    "    end_row = int(start_row + Np[0])\n",
    "    start_col = int(cen[1] - Np[1] // 2)\n",
    "    end_col = int(start_col + Np[1])\n",
    "    return x[start_row:end_row, start_col:end_col]\n",
    "\n",
    "def F(x):\n",
    "    # Apply 2D FFT on the first two dimensions and then shift the zero-frequency component to the center\n",
    "    return np.fft.fftshift(np.fft.fft2(x, axes=(0, 1)), axes=(0, 1))\n",
    "\n",
    "def Ft(x):\n",
    "    # Unshift the zero-frequency component and then apply 2D inverse FFT on the first two dimensions\n",
    "    return np.fft.ifft2(np.fft.ifftshift(x, axes=(0, 1)), axes=(0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 50\n",
    "P = np.complex128(w_NA)\n",
    "Ps = np.complex128(w_NA)\n",
    "spectrum_guess = F(np.sqrt(I[:,:,0]))\n",
    "O = upsamp(spectrum_guess)\n",
    "H0 = np.ones((roi_size_px, roi_size_px))\n",
    "r0 = 1\n",
    "alpha = 1\n",
    "beta = 1000\n",
    "step_size = 0.1\n",
    "scale = np.ones((1,Nimg));\n",
    "\n",
    "Np = np.array(I[:,:,0].shape)\n",
    "No = Np\n",
    "cen0 = np.round((No + 1) / 2).astype(int)\n",
    "\n",
    "Omax = np.abs(O[cen0[0], cen0[1]])\n",
    "print(Omax)\n",
    "\n",
    "def row(x):\n",
    "    return np.ravel(x)\n",
    "\n",
    "\n",
    "for _ in range(iters):\n",
    "    for m in range(Nimg):\n",
    "        # Initialize Psi for corresponding image, ROI determined by cen\n",
    "        Psi0 = np.zeros((Np[0], Np[1], r0), dtype=np.complex128)\n",
    "        Psi_scale = np.zeros((Np[0], Np[1], r0), dtype=np.complex128)\n",
    "        cen = np.zeros((2, r0))\n",
    "        scale0 = np.zeros(r0)\n",
    "        for p in range(r0):\n",
    "            cen[:, p] = cen0 - row(Ns[p, m, :])\n",
    "            scale0[p] = scale[p, m]\n",
    "            # Replace downsamp and other MATLAB-specific functions with Python equivalents\n",
    "            Psi0[:, :, p] = downsamp(O, cen[:, p], Np) * P * H0\n",
    "            Psi_scale[:, :, p] = np.sqrt(scale0[p]) * Psi0[:, :, p]\n",
    "\n",
    "        # Measured intensity\n",
    "        I_mea = np.squeeze(I[:, :, m])\n",
    "\n",
    "        # Compute field in real space\n",
    "        psi0 = np.squeeze(Ft(Psi_scale))\n",
    "\n",
    "        # Estimated intensity w/o correction term\n",
    "        I_est = np.abs(psi0) ** 2\n",
    "\n",
    "        # Replace these functions with Python equivalents\n",
    "        Psi = F(np.sqrt(I_mea / np.squeeze(scale0)) * np.exp(1j * np.angle(psi0)))\n",
    "        # Projection 2\n",
    "        dPsi = Psi - np.squeeze(Psi0)\n",
    "        Omax = np.abs(O[cen0[0], cen0[1]])\n",
    "        # Lambda function to replace the anonymous function in MATLAB\n",
    "        H0_replicated = np.squeeze(np.tile(H0, (1, 1, r0)))\n",
    "\n",
    "        P2 = lambda O, P, dpsi, Omax, cen: GDUpdate_Multiplication_rank1(O, P, dpsi, Omax, cen, Ps, alpha, beta, step_size)\n",
    "        O, P = P2(O, P, dPsi / H0_replicated, Omax, cen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_guess = Ft(O)\n",
    "plt.imshow(np.abs(object_guess)**2, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9], cmap='gray')\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('GN Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aberrated_FILTER = lens_init\n",
    "spectrum_guess = ift(np.sqrt(img[0]))\n",
    "spectrum_guess = spectrum_guess * FILTER\n",
    "object_guess = ft(spectrum_guess)\n",
    "lens_guess = np.double(FILTER)\n",
    "\n",
    "plt.imshow(np.abs(object_guess)**2, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9], cmap='gray')\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('Low-res measurement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_img = len(img) # assuming img is a list\n",
    "\n",
    "for k in range(100): # general loop\n",
    "    for i in range(N_img):\n",
    "        idx = i\n",
    "\n",
    "        S_n = object_guess\n",
    "        S_p = ft(S_n)\n",
    "\n",
    "        X0 = round(sx[idx]*fc_lens*Dx_m)\n",
    "        Y0 = round(sy[idx]*fc_lens*Dx_m)\n",
    "\n",
    "        mask = circshift2(FILTER, X0, Y0)\n",
    "        aberrated_mask = circshift2(aberrated_FILTER, X0, Y0)\n",
    "        phi_n = aberrated_mask * S_p\n",
    "        Phi_n = ift(phi_n)\n",
    "        Phi_np = np.sqrt(img[idx]) * np.exp(1j*np.angle(Phi_n))\n",
    "        phi_np = ft(Phi_np) # undo aberration\n",
    "\n",
    "        # S_p[mask] = phi_np[mask]\n",
    "        step = np.conj(aberrated_mask)/np.max(np.abs(aberrated_mask)**2)*(phi_np-phi_n)\n",
    "        S_p[mask] = S_p[mask] + step[mask]\n",
    "        S_np = ift(S_p)\n",
    "        object_guess = S_np\n",
    "\n",
    "        # plt.figure(figsize=(10,10)) # create a new figure in each iteration\n",
    "\n",
    "        # plt.subplot(221)\n",
    "        # plt.imshow(np.abs(object_guess), cmap=cm.gray)\n",
    "        # plt.title('Reconstructed amplitude')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # plt.subplot(222)\n",
    "        # plt.imshow(np.angle(object_guess), cmap=cm.gray)\n",
    "        # plt.axis('off')\n",
    "        # plt.title('Reconstructed phase')\n",
    "\n",
    "        # plt.subplot(223)\n",
    "        # plt.imshow(np.abs(ft(img[idx]))**0.1, cmap=cm.gray)\n",
    "        # plt.title('Current image PSD')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # plt.subplot(224)\n",
    "        # plt.imshow(np.abs(ft(S_np))**0.1, cmap=cm.gray)\n",
    "        # plt.title('Reconstructed angular spectrum')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # display(plt.gcf()) # display the current figure\n",
    "        # clear_output(wait = True) # clear the output of the current cell receiving output\n",
    "        # plt.pause(0.01) # pause for a short time\n",
    "        \n",
    "GS_recon = object_guess\n",
    "GS_recon_image = np.abs(object_guess)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imagecc(object_guess), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)', fontsize=10)\n",
    "plt.ylabel('y position (nm)', fontsize=10)\n",
    "plt.title('Reconstructed object', fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.abs(object_guess)**2, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9], cmap='gray')\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('GS reconstruction')\n",
    "plt.show()\n",
    "\n",
    "# display the center [256, 256] region, total size roi_size_px\n",
    "# param_nx = 256\n",
    "# object_center = object_guess[roi_size_px//2-param_nx//2:roi_size_px//2+param_nx//2, roi_size_px//2-param_nx//2:roi_size_px//2+param_nx//2]\n",
    "# plt.imshow(np.abs(object_center), cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.title('GS reconstruction')\n",
    "# plt.show()\n",
    "\n",
    "# Perform the refocusing\n",
    "# defocus_m = -1e-6\n",
    "# defocus_phase = np.exp(1j*2*np.pi/lambda_m*defocus_m*np.sqrt(1 -(lambda_m*Fx)**2 -(lambda_m*Fy)**2))\n",
    "# defocus_recon = ift(ft(object_guess) * defocus_phase)\n",
    "# defocused_image = np.abs(defocus_recon)**2\n",
    "# plt.imshow(defocused_image, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "# plt.xlabel('x position (nm)')\n",
    "# plt.ylabel('y position (nm)')\n",
    "# plt.title('Refocused image')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# np.save('./real_data/defocus_recon.npy', defocus_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt_obj = np.load(f'{folder}/gt.npy')\n",
    "ideal_FILTER = (Fx**2 + Fy**2) <= ((2)*fc_lens)**2\n",
    "gt_obj = ift(ft(gt_obj)*ideal_FILTER)\n",
    "\n",
    "plot_gt_cmp(GS_recon, gt_obj, x_m, y_m, freq_cpm, roi_size_px, frc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EPFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aberration initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can choose between 'plane', 'zernike', or 'file'\n",
    "init_option = 'plane'\n",
    "file_name = f'{folder}/gt_abe.npy'\n",
    "lens_init = get_lens_init(FILTER, init_option, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spectrum_guess = ift(np.sqrt(img[0]))\n",
    "spectrum_guess = spectrum_guess * FILTER\n",
    "object_guess = ft(spectrum_guess)\n",
    "lens_guess = lens_init\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "N_img = len(img) # assuming img is a list\n",
    "\n",
    "for k in range(10): # general loop\n",
    "    for i in range(N_img):\n",
    "        idx = i\n",
    "\n",
    "        S_n = object_guess\n",
    "        P_n = lens_guess\n",
    "\n",
    "        X0 = round(sx[idx]*fc_lens*Dx_m)\n",
    "        Y0 = round(sy[idx]*fc_lens*Dx_m)\n",
    "\n",
    "        phi_n = P_n * circshift2(ft(S_n), -X0, -Y0)\n",
    "\n",
    "        Phi_n = ift(phi_n)\n",
    "        Phi_np = np.sqrt(img[idx]) * np.exp(1j*np.angle(Phi_n))\n",
    "        phi_np = ft(Phi_np)\n",
    "\n",
    "        S_np = ift(ft(S_n) + alpha * \\\n",
    "            (np.conj(circshift2(P_n, X0, Y0)) / np.max(np.abs(circshift2(P_n, X0, Y0))**2)) * \\\n",
    "            (circshift2(phi_np, X0, Y0) - circshift2(phi_n, X0, Y0)))\n",
    "\n",
    "        P_np = P_n + beta * \\\n",
    "            (np.conj(circshift2(ft(S_n), -X0, -Y0)) / np.max(np.abs(circshift2(ft(S_n), -X0, -Y0))**2)) * \\\n",
    "            (phi_np - phi_n)\n",
    "\n",
    "        object_guess = S_np\n",
    "        lens_guess = P_np * FILTER\n",
    "\n",
    "        # plt.figure(figsize=(10,10)) # create a new figure in each iteration\n",
    "\n",
    "        # plt.subplot(221)\n",
    "        # plt.imshow(np.abs(object_guess), cmap=cm.gray)\n",
    "        # plt.title('Reconstructed amplitude')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # plt.subplot(222)\n",
    "        # plt.imshow(np.angle(object_guess), cmap=cm.gray)\n",
    "        # plt.axis('off')\n",
    "        # plt.title('Reconstructed phase')\n",
    "\n",
    "        # plt.subplot(223)\n",
    "        # plt.imshow(np.abs(ft(img[idx]))**0.1, cmap=cm.gray)\n",
    "        # plt.title('Current image PSD')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # plt.subplot(224)\n",
    "        # plt.imshow(np.abs(ft(S_np))**0.1, cmap=cm.gray)\n",
    "        # plt.title('Reconstructed angular spectrum')\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # display(plt.gcf()) # display the current figure\n",
    "        # clear_output(wait = True) # clear the output of the current cell receiving output\n",
    "        # plt.pause(0.01) # pause for a short time\n",
    "\n",
    "\n",
    "EPFR_recon = object_guess\n",
    "EPFR_recon_image = np.abs(object_guess)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagecc(object_guess), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('Reconstructed object')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.abs(object_guess)**2, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9], cmap='gray')\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('EPFR reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_aberration(np.angle(lens_guess), FILTER)\n",
    "PSF = np.abs(np.fft.fftshift(np.fft.fft2(lens_guess)))**2\n",
    "def plot_central_region(PSF, x_m, y_m, region_size=2e-6):\n",
    "    # Extract the central region of the PSF\n",
    "    x_center = (x_m[-1] + x_m[0]) / 2\n",
    "    y_center = (y_m[-1] + y_m[0]) / 2\n",
    "    x_indices = np.where((x_m >= x_center - region_size/2) & (x_m <= x_center + region_size/2))\n",
    "    y_indices = np.where((y_m >= y_center - region_size/2) & (y_m <= y_center + region_size/2))\n",
    "    central_PSF = PSF[y_indices[0][0]:y_indices[0][-1]+1, x_indices[0][0]:x_indices[0][-1]+1]\n",
    "\n",
    "    # Plot the central region\n",
    "    plt.imshow(central_PSF, extent=[x_m[x_indices[0][0]]*1e6, x_m[x_indices[0][-1]]*1e6, \n",
    "                                    y_m[y_indices[0][0]]*1e6, y_m[y_indices[0][-1]]*1e6])\n",
    "    plt.xlabel('x position (um)')\n",
    "    plt.ylabel('y position (um)')\n",
    "    plt.title('Central Region of PSF')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_central_region(PSF, x_m, y_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gt_cmp(EPFR_recon, gt_obj, x_m, y_m, freq_cpm, roi_size_px, frc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile-based recon without overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epfr_recon(object_guess, lens_guess, img, sx, sy, tile_size, tile_index):\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    N_img = len(img) # assuming img is a list\n",
    "    \n",
    "    # create tile mask for the target tile\n",
    "    tile_mask = np.zeros((roi_size_px, roi_size_px))\n",
    "    tile_mask[tile_index[0]:tile_index[0]+tile_size, tile_index[1]:tile_index[1]+tile_size] = 1\n",
    "    \n",
    "    object_guess = object_guess * tile_mask\n",
    "    for k in range(3): # general loop\n",
    "        for i in range(N_img):\n",
    "            idx = i\n",
    "\n",
    "            S_n = object_guess\n",
    "            P_n = lens_guess\n",
    "\n",
    "            X0 = round(sx[idx]*fc_lens*Dx_m)\n",
    "            Y0 = round(sy[idx]*fc_lens*Dx_m)\n",
    "\n",
    "            phi_n = P_n * circshift2(ft(S_n), -X0, -Y0)\n",
    "\n",
    "            Phi_n = ift(phi_n)\n",
    "            Phi_np = np.sqrt(img[idx]*tile_mask) * np.exp(1j*np.angle(Phi_n))\n",
    "            phi_np = ft(Phi_np)\n",
    "\n",
    "            S_np = ift(ft(S_n) + alpha * \\\n",
    "                (np.conj(circshift2(P_n, X0, Y0)) / np.max(np.abs(circshift2(P_n, X0, Y0))**2)) * \\\n",
    "                (circshift2(phi_np, X0, Y0) - circshift2(phi_n, X0, Y0)))\n",
    "\n",
    "            P_np = P_n + beta * \\\n",
    "                (np.conj(circshift2(ft(S_n), -X0, -Y0)) / np.max(np.abs(circshift2(ft(S_n), -X0, -Y0))**2)) * \\\n",
    "                (phi_np - phi_n)\n",
    "\n",
    "            object_guess = S_np\n",
    "            lens_guess = P_np * FILTER\n",
    "    \n",
    "    return object_guess, lens_guess\n",
    "\n",
    "\n",
    "tile_size = 332\n",
    "spectrum_guess = ift(np.sqrt(img[0]))\n",
    "spectrum_guess = spectrum_guess * FILTER\n",
    "object_guess = ft(spectrum_guess)\n",
    "lens_guess = lens_init\n",
    "total_recon = np.zeros((roi_size_px, roi_size_px)).astype(complex)\n",
    "for p in range(3):\n",
    "    for q in range(3):\n",
    "        tile_index = [p*tile_size, q*tile_size]\n",
    "        recon, lens_guess = epfr_recon(object_guess, lens_guess, img, sx, sy, tile_size, tile_index)\n",
    "        total_recon += recon\n",
    "\n",
    "np.save(f'{folder}/total_recon.npy', total_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gt_cmp(total_recon, gt_obj, x_m, y_m, frc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "file_path = glob.glob(f\"{folder}/*APIC*.*\")\n",
    "m = sio.loadmat(file_path[0])\n",
    "apic_recon = m['himMatching']\n",
    "pupil_recon = m['CTF_abe']\n",
    "zernike_recon = m['zernikeCoeff']\n",
    "\n",
    "# flip pupil recon\n",
    "pupil_recon = np.fliplr(pupil_recon)\n",
    "pupil_recon = np.flipud(pupil_recon)\n",
    "print(apic_recon.shape)\n",
    "apic_recon = apic_recon[::3, ::3]\n",
    "show_aberration(np.angle(pupil_recon), FILTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_aberration(np.angle(pupil_recon), FILTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zernike_recon = np.squeeze(np.array(zernike_recon))\n",
    "print(zernike_recon)\n",
    "def get_pupil_phase(z, pupil):\n",
    "    rows = np.any(pupil, axis=1)\n",
    "    cols = np.any(pupil, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    x = np.linspace(-1, 1, cmax-cmin+1)\n",
    "    y = np.linspace(-1, 1, rmax-rmin+1)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    local_pupil = np.where(X**2 + Y**2 <= 1, 1, 0)\n",
    "    abe_pupil = np.zeros_like(pupil).astype(np.float64)\n",
    "    abe_pupil[rmin:rmax+1, cmin:cmax+1] = compute_pupil_function(z, len(z)-1, X, Y) * local_pupil\n",
    "    return abe_pupil\n",
    "\n",
    "abe = get_pupil_phase(zernike_recon, FILTER)\n",
    "show_aberration(-abe, FILTER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code that is not yet cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile-based recon with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epfr_recon(object_guess, lens_guess, img, sx, sy):\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    N_img = len(img) # assuming img is a list\n",
    "\n",
    "    def pad(image):\n",
    "        return np.pad(image, ((0, roi_size_px - tile_size), (0, roi_size_px - tile_size)), 'constant', constant_values=0)\n",
    "    def crop(image):\n",
    "        return image[:tile_size, :tile_size]\n",
    "    \n",
    "    # pad images to roi_size_px\n",
    "    for i in range(N_img):\n",
    "        img[i] = pad(img[i])\n",
    "    \n",
    "    for k in range(3): # general loop\n",
    "        for i in range(N_img):\n",
    "            idx = i\n",
    "\n",
    "            S_n = pad(object_guess)\n",
    "            P_n = lens_guess\n",
    "\n",
    "            X0 = round(sx[idx]*fc_lens*Dx_m)\n",
    "            Y0 = round(sy[idx]*fc_lens*Dx_m)\n",
    "\n",
    "            phi_n = P_n * circshift2(ft(S_n), -X0, -Y0)\n",
    "\n",
    "            Phi_n = ift(phi_n)\n",
    "            Phi_np = np.sqrt(img[idx]) * np.exp(1j*np.angle(Phi_n))\n",
    "            phi_np = ft(Phi_np)\n",
    "\n",
    "            S_np = ift(ft(S_n) + alpha * \\\n",
    "                (np.conj(circshift2(P_n, X0, Y0)) / np.max(np.abs(circshift2(P_n, X0, Y0))**2)) * \\\n",
    "                (circshift2(phi_np, X0, Y0) - circshift2(phi_n, X0, Y0)))\n",
    "            P_np = P_n + beta * \\\n",
    "                (np.conj(circshift2(ft(S_n), -X0, -Y0)) / np.max(np.abs(circshift2(ft(S_n), -X0, -Y0))**2)) * \\\n",
    "                (phi_np - phi_n)\n",
    "            object_guess = crop(S_np)\n",
    "            lens_guess = P_np * FILTER\n",
    "    \n",
    "    return object_guess, lens_guess\n",
    "\n",
    "# divide the tiles\n",
    "# Adjusting the overlap to ensure uniform tile size\n",
    "\n",
    "tile_size = 255\n",
    "num_steps = 1 + roi_size_px // tile_size\n",
    "step_size = (roi_size_px - tile_size) // (num_steps - 1)\n",
    "\n",
    "overlap = (tile_size * num_steps - roi_size_px) // (num_steps - 1)\n",
    "step_size = tile_size - overlap\n",
    "\n",
    "total_size = tile_size * num_steps - overlap * (num_steps - 1)\n",
    "assert total_size == roi_size_px\n",
    "\n",
    "tile_stacks = {(i, j): [] for i in range(num_steps) for j in range(num_steps)}\n",
    "\n",
    "# Crop and organize by tile location\n",
    "for image in img:\n",
    "    for i in range(num_steps):\n",
    "        for j in range(num_steps):\n",
    "            x_start = i * step_size\n",
    "            y_start = j * step_size\n",
    "            tile = image[x_start:x_start+tile_size, y_start:y_start+tile_size]\n",
    "            tile_stacks[(i, j)].append(tile)\n",
    "\n",
    "\n",
    "spectrum_guess = ift(np.sqrt(img[0])) \n",
    "spectrum_guess = spectrum_guess * FILTER\n",
    "object_guess = ft(spectrum_guess)\n",
    "lens_guess = np.complex128(FILTER)\n",
    "# tile_lens = lens_guess[roi_size_px//4:3*roi_size_px//4, roi_size_px//4:3*roi_size_px//4]\n",
    "# tile_FILTER = FILTER[roi_size_px//4:3*roi_size_px//4, roi_size_px//4:3*roi_size_px//4]\n",
    "tiles = []\n",
    "for i in range(num_steps):\n",
    "    for j in range(num_steps):\n",
    "        x_start = i * step_size\n",
    "        y_start = j * step_size\n",
    "        tile_object = object_guess[x_start:x_start+tile_size, y_start:y_start+tile_size]\n",
    "        tile_recon, lens_recon = epfr_recon(tile_object, lens_guess, tile_stacks[(i,j)], sx, sy)\n",
    "        object_guess[x_start:x_start+tile_size, y_start:y_start+tile_size] = tile_recon\n",
    "        tiles.append(tile_recon)\n",
    "        lens_guess = lens_recon\n",
    "        \n",
    "\n",
    "plt.imshow(imagecc(object_guess), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('Tile-based reconstructed object')\n",
    "plt.colorbar()\n",
    "plt.show()    \n",
    "\n",
    "def create_weighted_mask(tile_size):\n",
    "    \"\"\"Create a linearly weighted mask for blending.\"\"\"\n",
    "    half_size = tile_size // 2\n",
    "    ramp = np.linspace(0.1, 1, half_size)  # starting from 0.1 to avoid zero weights\n",
    "    ramp = np.concatenate([ramp, ramp[::-1]])  # mirror the ramp for the other half\n",
    "    mask = np.outer(ramp, ramp)\n",
    "    return mask\n",
    "\n",
    "def stitch_tiles(tiles, num_steps, step_size, N):\n",
    "    \"\"\"Stitch tiles together using overlap.\"\"\"\n",
    "    mask = create_weighted_mask(tiles[0].shape[0])\n",
    "    stitched_image = np.complex128(np.zeros((N, N)))\n",
    "    weight_sum = np.zeros((N, N))\n",
    "\n",
    "    for i_idx in range(num_steps):\n",
    "        for j_idx in range(num_steps):\n",
    "            i = i_idx * step_size\n",
    "            j = j_idx * step_size\n",
    "            \n",
    "            stitched_image[i:i+tile_size, j:j+tile_size] += tiles[i_idx * num_steps + j_idx] * mask\n",
    "            weight_sum[i:i+tile_size, j:j+tile_size] += mask\n",
    "\n",
    "    # Normalize by the weights (to handle overlapping regions)\n",
    "    stitched_image /= weight_sum\n",
    "\n",
    "    return stitched_image\n",
    " \n",
    "stiched_object = stitch_tiles(tiles, num_steps, step_size, roi_size_px)\n",
    "plt.imshow(np.abs(stiched_object)**2, extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('Stitched image')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagecc(object_guess), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('y position (nm)')\n",
    "plt.title('Tile-based reconstructed object')\n",
    "plt.colorbar()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compare reconstruction with ground truth\n",
    "Also plot FRC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obj_lines = np.load('obj_lines.npy')\n",
    "ideal_FILTER = (Fx**2 + Fy**2) <= ((1+np.sqrt(2))*fc_lens)**2\n",
    "object_gt = ift(ft(obj_lines)*ideal_FILTER)\n",
    "\n",
    "plt.figure(figsize=(10, 10))  # Increase the figure size\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(imagecc(object_guess), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)', fontsize=10)\n",
    "plt.ylabel('y position (nm)', fontsize=10)\n",
    "plt.title('Reconstructed object', fontsize=12)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(imagecc(object_gt), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)', fontsize=10)\n",
    "plt.ylabel('y position (nm)', fontsize=10)\n",
    "plt.title('Ground truth object (bandlimited)', fontsize=12)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)  # Increase space between subplots\n",
    "plt.tight_layout()  # Automatically adjust subplot parameters for better fit\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "im_guess = np.abs(object_guess)**2\n",
    "im_gt = np.abs(object_gt)**2\n",
    "im_guess_normalized = im_guess / np.std(im_guess)\n",
    "im_gt_normalized = im_gt / np.std(im_gt)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_m*1e9, np.abs(im_guess_normalized[160,:]))\n",
    "plt.plot(x_m*1e9, np.abs(im_gt_normalized[160,:]))\n",
    "plt.title('Slice 160')\n",
    "plt.xlabel('x position (nm)')\n",
    "plt.ylabel('normalized intensity (a.u.)')\n",
    "plt.legend(['image guess', 'ground truth'])\n",
    "plt.show()\n",
    "\n",
    "rmse_normalized = np.sqrt(np.sum((im_guess_normalized-im_gt_normalized)**2))/np.sqrt(np.sum(im_gt_normalized**2))\n",
    "print(np.log(rmse_normalized))\n",
    "\n",
    "frc_array, halfbit_threshold = frc(im_guess_normalized, im_gt_normalized)\n",
    "plt.figure()\n",
    "plt.plot(freq_cpm[roi_size_px//2:], np.abs(frc_array))\n",
    "plt.axhline(halfbit_threshold, color='r', linestyle='--', label='Half-bit threshold')\n",
    "plt.title('Fourier ring correlation')\n",
    "plt.xlabel('Spatial frequency (nm-1)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compare reconstructed pupil with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10))  # adjust the figsize if needed\n",
    "\n",
    "# First subplot\n",
    "im = ax[0].imshow(imagecc(lens_init), cmap='hsv')\n",
    "ax[0].set_title('Initial pupil')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "# Second subplot\n",
    "im = ax[1].imshow(imagecc(lens_guess), cmap='hsv')\n",
    "ax[1].set_title('Reconstructed pupil')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "# Third subplot\n",
    "im = ax[2].imshow(imagecc(aberrated_FILTER), cmap='hsv')\n",
    "ax[2].set_title('Ground truth pupil')\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot zoomed in reconstructed pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "show_size = roi_size_px\n",
    "plt.imshow(imagecc(lens_guess[roi_size_px//2-show_size//2:roi_size_px//2+show_size//2, roi_size_px//2-show_size//2:roi_size_px//2+show_size//2]), cmap='hsv')\n",
    "plt.title('Reconstructed pupil (zoomed in)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare GS and EPFR reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))  # Increase the figure size\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(imagecc(GS_recon_image), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)', fontsize=10)\n",
    "plt.ylabel('y position (nm)', fontsize=10)\n",
    "plt.title('GS reconstruction', fontsize=12)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(imagecc(EPFR_recon_image), extent=[x_m[0]*1e9, x_m[-1]*1e9, y_m[0]*1e9, y_m[-1]*1e9])\n",
    "plt.xlabel('x position (nm)', fontsize=10)\n",
    "plt.ylabel('y position (nm)', fontsize=10)\n",
    "plt.title('EPFR reconstruction', fontsize=12)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)  # Increase space between subplots\n",
    "plt.tight_layout()  # Automatically adjust subplot parameters for better fit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp_euv",
   "language": "python",
   "name": "fp_euv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
